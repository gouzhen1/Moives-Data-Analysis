{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Analysis of Major Revenue Driving Factors in American Movies\n",
    "#### by Stephen Gou\n",
    "#### Student Number: 1000382908\n",
    "### Questions\n",
    "1. Is there a statistically significant difference between the mean revenues of NY critic picks and non-picks movies?\n",
    "2. Do reviews of NY critic picks display a different set of sentiments than that of non-picks?\n",
    "3. What are the major characteristics of a modern American movie that affect its deomestic lifetime revenue? Modern is defined here as after 1990.\n",
    "\n",
    "### Data Collection\n",
    "- OMDb API provies a good baseline meta data about movies including release date, runtime, genre, director, writer, actors, production companies, and opening box office. However, several data of interests are missing, e.g. life-time revenue (it only provides opening box office) and budget.\n",
    "\n",
    "- To supplement OMDb, I found The Movie Dataset on Kaggle:\n",
    "    https://www.kaggle.com/rounakbanik/the-movies-dataset#movies_metadata.csv\n",
    "    This data was collected from TMDB. It contains revenue, budget, multiple genre tags, and keywords data.\n",
    "\n",
    "- NY movie reviews can be accessed through its API.\n",
    "\n",
    "- Text Blob for sentiment analysis https://textblob.readthedocs.io/en/dev/quickstart.html\n",
    "\n",
    "### EDA\n",
    "1. Plot the distribution of revenues of critic-picks vs non-picks.\n",
    "    \n",
    "2. Generate frequencies of words with different sentiments.\n",
    "\n",
    "3. Feature selection and transformation for analyzing movie revenues factors\n",
    " - Pick out relevant features in the data for predicting the revenues through intuition, e.g. genre, director, keywords and actors.\n",
    "\n",
    " - Examine the validity of important data like revenue. For example, are these revenue figures inflation adjusted? Are they domestic and lifetime revenues? Validate some revenues with other data source like Box Office Mojo.\n",
    "\n",
    " - Think about how to represent and transform certain features to be ready for modelling: For instance, actors. One way to use it meaningfully is to pull external references and assign a \"popularity score\" to each actor.\n",
    "    \n",
    " - Keywords is another example that we have to explore its range and values and figure out how to incoporate it into our model. How many unique ones are in total and how many keywords are associated with each movie? \"The Dark Knight Rises\" has 21 keywords associated with it, including \"dc comics\", \"terrorist\", \"gotham city\", \"catwoman\"and etc. Some words like \"dc comics\" might offer very good predictive value since it's associated with many movies, while others like \"gotham city\" and \"catman\" might be too specific. Here we might need to plot a histogram of frequencies of all popular keywords.\n",
    "\n",
    "### Analysis\n",
    "**1. Is there a statistically significant difference between the mean revenues of NY critic picks and non-picks movies?**\n",
    "    \n",
    "    Conduct a t-test on the mean revenue of critic-picks and determine if there's statistically significant difference.\n",
    "\n",
    "\n",
    "**2. Do reviews of NY critic picks display a different set of sentiments than that of non-picks?**\n",
    "    \n",
    "    Compare the top most-frequent key words to picks vs non-picks.\n",
    "    \n",
    "    \n",
    "**3. What are the major characteristics of a modern American movie that affect its deomestic lifetime revenue?**\n",
    "- Construct a linear regression model that fits a movie's features to its revenue. Categorical features like genre tags, and key words will be one hot encoded. Reason about possible interaction terms and include them in the model. \n",
    "- Examine coefficients and their corresponding p-values to identify the most influential features that drive revenue.\n",
    "- Finally, test for likely confounders. For instance, genre might affect a movie's revenue and the type of directors at the same time.\n",
    "- Try random forest of regression trees and compare performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "## Methods\n",
    "## Cleaning\n",
    "## EDA\n",
    "## Feature Selection and Mapping\n",
    "\n",
    "## Results\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for importing, basic trimming and observation of data from TMDB and OMDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 74, saw 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e143e5f3a623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#NY Reviews Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mny_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"https://github.com/gouzhen1/Moives-Data-Analysis/blob/master/NY%20Movie%20Reviews.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mny_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'display_title'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mny_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mny_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mpaa_rating'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'critics_pick'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 74, saw 4\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "    \n",
    "#NY Reviews Dataset\n",
    "ny_df = pd.read_csv(r\"https://github.com/gouzhen1/Moives-Data-Analysis/blob/master/NY%20Movie%20Reviews.csv\")\n",
    "ny_df.rename(columns={'display_title':'title'},inplace=True)\n",
    "ny_df = ny_df[['title','mpaa_rating','critics_pick']]\n",
    "print(ny_df.shape)\n",
    "\n",
    "#Wrangle actors and director\n",
    "#TMDB Credits Dataset (for cast and director)\n",
    "tmdb_credits_df = pd.read_csv('https://github.com/gouzhen1/Moives-Data-Analysis/blob/master/tmdb_5000_credits.csv')\n",
    "actors_rank = pd.read_csv('https://github.com/gouzhen1/Moives-Data-Analysis/blob/master/Top%201000%20Actors%20and%20Actresses.csv')['Name'].tolist()\n",
    "directors_rank = pd.read_csv('https://github.com/gouzhen1/Moives-Data-Analysis/blob/master/All%20Time%20Director%20Rankings.csv')['Name'].tolist()\n",
    "total_actors = len(actors_rank)\n",
    "total_directors = len(directors_rank)\n",
    "        \n",
    "def transform_cast(df):\n",
    "    cast_json = df['cast']\n",
    "    parsed_cast = json.loads(cast_json)\n",
    "    score = 0.\n",
    "    count = 0 \n",
    "    for cast in parsed_cast:\n",
    "        actor = cast['name']\n",
    "        if actor in actors_rank:\n",
    "            #discounted for later casts\n",
    "            score += (0.8 ** count) * (1. - (actors_rank.index(actor)/total_actors))\n",
    "        count += 1\n",
    "    return score\n",
    "tmdb_credits_df['cast_score'] = tmdb_credits_df.apply(transform_cast, axis = 1)\n",
    "\n",
    "def transform_crew(df):\n",
    "    crew_json = df['crew']\n",
    "    parsed_crew = json.loads(crew_json)\n",
    "    score = 0.\n",
    "    for crew in parsed_crew:\n",
    "        if crew['department'] == 'Directing' and crew['job'] == 'Director':\n",
    "            director = crew['name']\n",
    "            if director in directors_rank:\n",
    "                score += (1. - (directors_rank.index(director)/total_directors))\n",
    "            break\n",
    "    return score\n",
    "\n",
    "tmdb_credits_df['director_score'] = tmdb_credits_df.apply(transform_crew, axis = 1)\n",
    "tmdb_credits_df = tmdb_credits_df[['title','cast_score','director_score']]\n",
    "\n",
    "#TMDB Main Dataset\n",
    "tmdb_df = pd.read_csv('https://github.com/gouzhen1/Moives-Data-Analysis/blob/master/tmdb_5000_movies.csv')\n",
    "tmdb_df['release_date'] = pd.to_datetime(tmdb_df['release_date'])\n",
    "tmdb_df.drop(tmdb_df[tmdb_df['release_date'].dt.year < 1990].index, inplace=True)\n",
    "tmdb_df = tmdb_df[tmdb_df['revenue'] > 0]\n",
    "tmdb_df = tmdb_df.merge(ny_df,how='left')\n",
    "    \n",
    "#process and filter countries\n",
    "def process_country(df):\n",
    "    country_json = df['production_countries']\n",
    "    parsed_country = json.loads(country_json)\n",
    "    if len(parsed_country) > 0:\n",
    "        return parsed_country[0]['name']\n",
    "    else:\n",
    "        return None\n",
    "tmdb_df['production_countries'] = tmdb_df.apply(process_country, axis = 1)\n",
    "tmdb_df = tmdb_df[tmdb_df['production_countries'] =='United States of America']\n",
    "tmdb_df.drop(columns='production_countries',inplace=True)\n",
    "\n",
    "#wrangle genre\n",
    "genre_dict = {}\n",
    "def transform_genre(df):\n",
    "    genre_json = df['genres']\n",
    "    parsed_genre = json.loads(genre_json)\n",
    "    result = []\n",
    "    for genre in parsed_genre:\n",
    "        genre_name = genre['name']\n",
    "        result.append(genre_name)\n",
    "        if genre_name not in genre_dict:\n",
    "            genre_dict[genre_name] = 1\n",
    "        else:\n",
    "            genre_dict[genre_name] += 1\n",
    "    \n",
    "    return result\n",
    "tmdb_df['genres'] = tmdb_df.apply(transform_genre, axis = 1)\n",
    "#drop very low rare genres\n",
    "del genre_dict['Foreign']\n",
    "for genre in genre_dict:\n",
    "    tmdb_df['is_' + genre] = tmdb_df['genres'].transform(lambda x: int(genre in x))\n",
    "tmdb_df.drop(columns=['genres'],inplace=True)\n",
    "\n",
    "#map mpaa rating\n",
    "rating_df = pd.get_dummies(tmdb_df['mpaa_rating'],prefix='rating')\n",
    "tmdb_df = tmdb_df.merge(rating_df,left_index=True,right_index=True)\n",
    "tmdb_df.drop(columns=['mpaa_rating'],inplace=True)\n",
    "\n",
    "#inflation adjust\n",
    "cpi_df = pd.read_csv('https://github.com/gouzhen1/Moives-Data-Analysis/blob/master/Annual%20CPI.csv')\n",
    "cpi_df = cpi_df.set_index('DATE')\n",
    "cpi_dict = cpi_df.to_dict()['CPIAUCSL']\n",
    "def get_cpi_adjusted(df):\n",
    "    year = df['release_date'].year\n",
    "    revenue = df['revenue']\n",
    "    return cpi_dict['2017-01-01']/cpi_dict['{}-01-01'.format(year)] * revenue\n",
    "\n",
    "tmdb_df['revenue_a'] = tmdb_df.apply(get_cpi_adjusted,axis=1)\n",
    "tmdb_df = tmdb_df.drop(columns = ['release_date','original_language','popularity','homepage','overview','spoken_languages','tagline','original_title','vote_average','vote_count','id','status','production_companies','keywords','revenue'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2033, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "      <th>critics_pick</th>\n",
       "      <th>is_action</th>\n",
       "      <th>is_adventure</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_science fiction</th>\n",
       "      <th>is_crime</th>\n",
       "      <th>is_drama</th>\n",
       "      <th>...</th>\n",
       "      <th>is_documentary</th>\n",
       "      <th>rating_g</th>\n",
       "      <th>rating_nc-17</th>\n",
       "      <th>rating_not rated</th>\n",
       "      <th>rating_pg</th>\n",
       "      <th>rating_pg-13</th>\n",
       "      <th>rating_r</th>\n",
       "      <th>revenue_a</th>\n",
       "      <th>cast_score</th>\n",
       "      <th>director_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.185239e+09</td>\n",
       "      <td>1.141077</td>\n",
       "      <td>0.836364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.136173e+09</td>\n",
       "      <td>1.943331</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250000000</td>\n",
       "      <td>165.0</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.158438e+09</td>\n",
       "      <td>3.147587</td>\n",
       "      <td>0.709091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260000000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.033879e+08</td>\n",
       "      <td>1.339893</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258000000</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.053261e+09</td>\n",
       "      <td>1.381308</td>\n",
       "      <td>0.490909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget  runtime                                     title  critics_pick  \\\n",
       "0  237000000    162.0                                    Avatar           1.0   \n",
       "1  300000000    169.0  Pirates of the Caribbean: At World's End           0.0   \n",
       "2  250000000    165.0                     The Dark Knight Rises           1.0   \n",
       "3  260000000    132.0                               John Carter           0.0   \n",
       "4  258000000    139.0                              Spider-Man 3           0.0   \n",
       "\n",
       "   is_action  is_adventure  is_fantasy  is_science fiction  is_crime  \\\n",
       "0          1             1           1                   1         0   \n",
       "1          1             1           1                   0         0   \n",
       "2          1             0           0                   0         1   \n",
       "3          1             1           0                   1         0   \n",
       "4          1             1           1                   0         0   \n",
       "\n",
       "   is_drama       ...        is_documentary  rating_g  rating_nc-17  \\\n",
       "0         0       ...                     0         0             0   \n",
       "1         0       ...                     0         0             0   \n",
       "2         1       ...                     0         0             0   \n",
       "3         0       ...                     0         0             0   \n",
       "4         0       ...                     0         0             0   \n",
       "\n",
       "   rating_not rated  rating_pg  rating_pg-13  rating_r     revenue_a  \\\n",
       "0                 0          0             1         0  3.185239e+09   \n",
       "1                 0          0             1         0  1.136173e+09   \n",
       "2                 0          0             1         0  1.158438e+09   \n",
       "3                 0          0             1         0  3.033879e+08   \n",
       "4                 0          0             1         0  1.053261e+09   \n",
       "\n",
       "   cast_score  director_score  \n",
       "0    1.141077        0.836364  \n",
       "1    1.943331        0.400000  \n",
       "2    3.147587        0.709091  \n",
       "3    1.339893        0.000000  \n",
       "4    1.381308        0.490909  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(tmdb_df.shape)\n",
    "tmdb_df = tmdb_df.merge(tmdb_credits_df,how='left')\n",
    "tmdb_df.columns = map(str.lower, tmdb_df.columns)\n",
    "tmdb_df.to_csv('wrangled_dataset.csv')\n",
    "tmdb_df.describe()\n",
    "tmdb_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              revenue_a   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     8.932\n",
      "Date:                Wed, 24 Oct 2018   Prob (F-statistic):            0.00284\n",
      "Time:                        23:25:05   Log-Likelihood:                -42139.\n",
      "No. Observations:                2035   AIC:                         8.428e+04\n",
      "Df Residuals:                    2033   BIC:                         8.429e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept       1.647e+08   5.32e+06     30.945      0.000    1.54e+08    1.75e+08\n",
      "is_documentary  -1.31e+08   4.38e+07     -2.989      0.003   -2.17e+08    -4.5e+07\n",
      "==============================================================================\n",
      "Omnibus:                     1725.246   Durbin-Watson:                   0.740\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            63319.468\n",
      "Skew:                           3.816   Prob(JB):                         0.00\n",
      "Kurtosis:                      29.239   Cond. No.                         8.30\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "results = smf.ols('revenue_a ~ is_documentary', data=tmdb_df).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codes for scraping, dont run. saved to csv file.\n",
    "NYT_API_KEY = '53223e11b006467490bde835d45b0c74'\n",
    "\n",
    "all_ny_df = []\n",
    "for offset in range(0,8000,20):\n",
    "    url = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=1990-01-01;2016-12-31&offset={0}&api-key=ae71411b586e4f9c82502e7e782b122d'.format(offset)\n",
    "    ny_json = pd.read_json(url, orient = 'records')\n",
    "    ny_df = json_normalize(ny_json['results'])\n",
    "    if ny_df.empty:\n",
    "        break\n",
    "    all_ny_df.append(ny_df)\n",
    "\n",
    "ny_df = pd.concat(all_ny_df)\n",
    "print(ny_df.tail())\n",
    "ny_df.to_csv('NY Movie Reviews.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "title = 't=' + nytdata['display_title'][1].replace(' ', '+')\n",
    "req = 'http://www.omdbapi.com/?apikey='+ OMDB_API_KEY + '&'+ title\n",
    "print(pd.read_json(req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMDB_API_KEY = 'd42886f4'\n",
    "\n",
    "def fetch_omdb(title):\n",
    "    title = 't=' + title.replace(' ', '+')\n",
    "    print (title)\n",
    "    req = 'http://www.omdbapi.com/?apikey='+ OMDB_API_KEY + '&'+ title\n",
    "    omdb_df = pd.read_json(req)\n",
    "    return omdb_df\n",
    "\n",
    "count = 0\n",
    "omdb_df_list = []\n",
    "for title in tmdb_df['title'].tolist():\n",
    "    count += 1\n",
    "    omdb_df_list.append(fetch_omdb(title))\n",
    "    if count > 5:\n",
    "        break\n",
    "        \n",
    "complete = pd.concat(omdb_df_list,axis=0)\n",
    "complete.to_csv('omdb_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(3,2), columns=['A', 'B'])\n",
    "print(df.head())\n",
    "print(type(df.iloc[0]))\n",
    "print(type(df['A']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
